import { Injectable } from '@nestjs/common';
import { BlockchainService } from '../blockchain.service';
import { RetryService } from './retry.service';

/**
 * â° BLOCK TIMESTAMP SERVICE - EFFICIENT TIMESTAMP FETCHER
 * 
 * Specialized service for fetching block timestamps in an optimized, batched manner.
 * Essential for adding temporal metadata to token information.
 * 
 * ğŸ¯ MAIN RESPONSIBILITIES:
 * - Fetch block timestamps for multiple blocks efficiently
 * - Implement batching to optimize RPC usage
 * - Cache results to avoid duplicate requests
 * - Handle rate limiting with delays
 * 
 * âš¡ PERFORMANCE OPTIMIZATIONS:
 * - Batch processing (10 blocks at a time)
 * - Parallel fetching within batches
 * - Rate limiting delays (200ms between batches)
 * - In-memory caching with Map structure
 * 
 * ğŸ”„ BATCHING STRATEGY:
 * - Process 10 blocks simultaneously
 * - 200ms delay between batches
 * - Retry logic for network failures
 * - Return cached Map for O(1) lookups
 * 
 * ğŸ’¡ USE CASES:
 * - Adding creation timestamps to token metadata
 * - Temporal analysis of token launches
 * - Historical data enrichment
 */
@Injectable()
export class BlockTimestampService {
  // âš¡ Performance tuning constants
  private static readonly BATCH_SIZE = 10;   // Blocks processed simultaneously
  private static readonly BATCH_DELAY = 200; // Milliseconds between batches

  constructor(
    // ğŸ”— Core blockchain service for fetching block data
    private readonly blockchainService: BlockchainService,
    
    // ğŸ”„ Retry service for network resilience
    private readonly retryService: RetryService,
  ) {}

  /**
   * â° FETCH BLOCK TIMESTAMPS IN OPTIMIZED BATCHES
   * 
   * Efficiently fetches timestamps for multiple blocks using a batching strategy.
   * Returns a Map for O(1) timestamp lookups during token processing.
   * 
   * ğŸ”„ BATCHING WORKFLOW:
   * 1. ğŸ“¦ Split block numbers into batches of 10
   * 2. ğŸš€ Process each batch in parallel
   * 3. ğŸ’¾ Cache results in Map structure
   * 4. â±ï¸ Apply rate limiting delays
   * 5. ğŸ“Š Return complete timestamp cache
   * 
   * âš¡ EFFICIENCY BENEFITS:
   * - Reduces RPC calls by batching
   * - Parallel processing within batches
   * - O(1) lookup performance
   * - Network-friendly rate limiting
   * 
   * @param blockNumbers - Array of block numbers to fetch timestamps for
   * @returns Map with block number â†’ timestamp mapping
   */
  async fetchBlockTimestamps(blockNumbers: bigint[]): Promise<Map<bigint, bigint>> {
    const cache = new Map<bigint, bigint>();

    // ğŸ”„ Process blocks in batches for optimal performance
    for (let i = 0; i < blockNumbers.length; i += BlockTimestampService.BATCH_SIZE) {
      const batch = blockNumbers.slice(i, i + BlockTimestampService.BATCH_SIZE);
      
      // ğŸš€ Create parallel promises for batch processing
      const promises = batch.map((blockNumber) =>
        this.retryService.retryWithBackoff({
          fn: () => this.blockchainService.getBlock(blockNumber),
        }),
      );

      // â³ Wait for all blocks in batch to complete
      const blocks = await Promise.all(promises);
      
      // ğŸ’¾ Cache the timestamp results
      blocks.forEach((block, index) => {
        cache.set(batch[index], block.timestamp);
      });

      // â±ï¸ Rate limiting: Small delay between batches
      if (i + BlockTimestampService.BATCH_SIZE < blockNumbers.length) {
        await new Promise((resolve) => 
          setTimeout(resolve, BlockTimestampService.BATCH_DELAY)
        );
      }
    }

    return cache;
  }
}